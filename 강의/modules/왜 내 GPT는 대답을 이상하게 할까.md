---
type: module
---

## 왜 내 GPT는 대답을 이상하게 할까?

### Knowledge Cut-off

- LLM은 특정 시점까지의 데이터를 학습하고 있기 때문에, 그 이후에 일어난 일은 잘 모름
- 이를 Knowledge Cut-off라 하며, RAG 등을 사용해 데이터를 보강하는 것으로 해결할 수 있다

---

### 환각 현상

- 환각은 LLM의 오류가 아닌, LLM의 태생적 한계
	- 우리는 LLM과 대화를, 혹은 질문을 하는 것이 아님. LLM이 단지 우리가 만들어놓은 몇 단어를 토대로 글을 완성시키는 것뿐.

> 대형언어모델(LLM)은 확률적 정보에 따라 방대한 훈련 데이터에서 관찰한 언어 형식의 시퀀스를 우연히 꿰맞추는 시스템이다. 의미를 되새길 필요없는 확률론적 앵무새(Stochastic Parrots)다. ***- 에밀리 M. 벤더, 언어학자***

### 질문이 잘못됨

- 우리는 자신에 대한 기대와는 달리 비논리적이며, 의사소통에 게으르다.
- 동문서답, "맛집 알려드릴까요?"

---

### 챗봇의 기억력

- LLM을 구동하는 데에는 많은 자원이 필요하며, 대화가 길어지면 긴 대화를 처리하기 어려워함
- 답변의 생성은 매번 독립시행임을 생각할 때
	- 기존의 대화를 요약해서 사전 프롬프트(pre-prompt)로 제공하고 있을 것
	- [Exposing pre-prompt](https://www.reddit.com/r/ChatGPT/comments/12fnqhd/exposing_preprompt/?rdt=53762)
	- [Gaslighting AI into 2+2=5](https://www.youtube.com/watch?v=3wlvNfTNgB8)

### 맥락에 대한 컨트롤

- 대화의 맥락은 마치 미로를 탐색하는 것처럼 선형적 구성을 따르기 때문에 
- 원하는 결과를 얻기 위해 *대화의 맥락을 컨트롤할 필요가 있고*, 
- 맥락이 오염된 경우 아예 새로 시작하는 것이 좋음. 

---

### AI 윤리

- 생성형 AI의 출현과 함께 야기된 딥페이크 등의 AI 윤리 위반에 대해 대부분의 상용 AI들은 비윤리적 답변을 통제하고 있음
	- 가짜 뉴스
	- 딥페이크
	- 반인륜적 주제
- 이러한 제한사항은 탈옥(Jailbreak)이라 불리는 적대적 프롬프팅에 의해 해제되기도 함
	- 개발자가 LLM을 완전히 통제할 수 없기에

![](../attachments/gpt-deep-fake-trump-got-caught.png)